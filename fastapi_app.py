# fastapi_app.py

import os
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from starlette.websockets import WebSocketState
from pydantic import BaseModel
from typing import Optional
import asyncio
import json

# å¤ç”¨æˆ‘ä»¬ä¹‹å‰å®šä¹‰çš„æ‰€æœ‰ LangChain å’Œ Redis ç›¸å…³ç»„ä»¶
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain_community.chat_message_histories import RedisChatMessageHistory
from langchain.memory import ConversationBufferMemory
from aip import AipSpeech

# --- 1. åˆå§‹åŒ–æ‰€æœ‰å®¢æˆ·ç«¯å’ŒæœåŠ¡ (æ— å˜åŒ–) ---
# ç™¾åº¦è¯­éŸ³ API
APP_ID = os.getenv("BAIDU_VOICE_APP_ID")
API_KEY = os.getenv("BAIDU_VOICE_API_KEY")
SECRET_KEY = os.getenv("BAIDU_VOICE_SECRET_KEY")
print(APP_ID)
speech_client = AipSpeech(APP_ID, API_KEY, SECRET_KEY)

# --- 2. æ ¸å¿ƒä¸šåŠ¡é€»è¾‘å‡½æ•° (æ— å˜åŒ–, ä½†åšäº†ç²¾ç®€ä¿®æ­£) ---
def transcribe_audio_stream(audio_bytes: bytes) -> str:
    """æ¥æ”¶PCMéŸ³é¢‘æµï¼Œè°ƒç”¨ç™¾åº¦ASR APIè¿›è¡Œè½¬å½•ã€‚"""
    # dev_pid=1537 æ˜¯æ™®é€šè¯æ¨¡å‹
    stt_result = speech_client.asr(audio_bytes, 'pcm', 16000, {'dev_pid': 1537})
    if stt_result and stt_result.get('err_no') == 0 and stt_result.get('result'):
        return stt_result['result'][0]
    else:
        print(f"! STT (ASR) é”™è¯¯: {stt_result}")
        return ""

def synthesize_speech_stream(text: str) -> bytes:
    """æ¥æ”¶æ–‡æœ¬ï¼Œè°ƒç”¨ç™¾åº¦TTS APIåˆæˆè¯­éŸ³ã€‚"""
    tts_result = speech_client.synthesis(
        text, 'zh', 1, 
        {
            'vol': 5, 
            'per': 5118, 
            'pit': 5, 
            'aue': 4,
            'audio_ctrl': {"sampling_rate":16000}}
    )
    if not isinstance(tts_result, dict):
        return tts_result
    else:
        print(f"! TTS (æ–‡æœ¬è½¬è¯­éŸ³) é”™è¯¯: {tts_result}")
        return b""


# --- 1. é…ç½®ä¸åˆå§‹åŒ– (å¤ç”¨é€»è¾‘) ---
LLM_ENDPOINT_ID = os.getenv("LLM_ENDPOINT_ID")
llm = ChatOpenAI(
    model=LLM_ENDPOINT_ID,
    base_url=os.getenv("LLM_BASE_URL"),
    api_key=os.getenv("LLM_API_KEY"),
    temperature=0.7
)

template = """
# Role (è§’è‰²è®¾å®š)
ä½ å«â€œéŸ©ç«‹â€ï¼Œæ˜¯ä¸€ä½åœ¨æ¯”äºšè¿ªå·¥ä½œå¤šå¹´çš„èµ„æ·±æ±½è½¦å·¥ç¨‹å¸ˆï¼Œå‚ä¸è¿‡è…¾åŠ¿ Z9GT çš„ç ”å‘ã€‚åŒæ—¶ï¼Œä½ æ˜¯ä¸€ä½è€å¿ƒçš„ä¸­æ–‡ç§æ•™ã€‚ä½ çš„å­¦ç”Ÿå« Emmaï¼Œå¥¹æƒ³å­¦ä¹ æ–°èƒ½æºæ±½è½¦è®¾è®¡ã€‚

# Style & Constraints (é£æ ¼çº¦æŸ)
1. ä¼˜å…ˆä¸“ä¸šæ€§ï¼šä»¥ä¸¥è°¨ã€ä¸“ä¸šçš„å£å»å›ç­”ã€‚
2. è¯­è¨€æ•™å­¦ï¼šå¦‚æœ Emma çš„ä¸­æ–‡æœ‰æ˜æ˜¾é”™è¯¯ï¼Œå¿…é¡»åœ¨å›ç­”å®Œé—®é¢˜åï¼Œå¦èµ·ä¸€æ®µï¼Œæ¸©æŸ”åœ°æŒ‡å‡ºå¹¶ä¿®æ­£ã€‚

# Context (å¯¹è¯å†å²)
{chat_history}

# Current Turn (å½“å‰å¯¹è¯)
Emma: {question}
éŸ©ç«‹:
"""
prompt = PromptTemplate(input_variables=["chat_history", "question"], template=template)

REDIS_URL = os.getenv("REDIS_URL", "redis://redis:6379/0")  # Dockerç¯å¢ƒä¸‹ä½¿ç”¨æœåŠ¡å

# åˆ›å»º FastAPI åº”ç”¨å®ä¾‹
app = FastAPI()

# LEDæ§åˆ¶å™¨è¿æ¥ï¼ˆç”¨äºè½¬å‘è¯´è¯çŠ¶æ€ï¼‰
led_controller_connection: Optional[WebSocket] = None

# --- 2. ä½¿ç”¨ Pydantic å®šä¹‰è¯·æ±‚ä½“æ¨¡å‹ ---
class ChatRequest(BaseModel):
    user_input: str
    user_id: str

# --- 3. Redis é©±åŠ¨çš„ Agent æ ¸å¿ƒ (åŒæ­¥å‡½æ•°) ---
# å¤ç”¨æˆ‘ä»¬ 12.1.2 èŠ‚çš„ get_ai_response_with_redis å‡½æ•°
def get_ai_response_with_redis(user_input: str, user_id: str) -> str:
    """
    æ¥æ”¶ç”¨æˆ·è¾“å…¥å’Œ user_id, ä» Redis åŠ è½½è®°å¿†, è®¡ç®—åå°†æ›´æ–°åçš„è®°å¿†å­˜å› Redisã€‚
    """
    # 1. åˆ›å»º Redis è®°å¿†å¯¹è±¡
    # session_id å°±æ˜¯æˆ‘ä»¬çš„ user_id, LangChain ä¼šç”¨å®ƒä½œä¸º Redis çš„ Key
    history = RedisChatMessageHistory(
        session_id=user_id,
        url=REDIS_URL
    )
    
    # 2. åˆ›å»º Memory å®ä¾‹, å¹¶æ³¨å…¥ Redis å†å²
    memory = ConversationBufferMemory(
        memory_key="chat_history", 
        chat_memory=history
    )

    # 3. åˆ›å»º Chain (æ ¸å¿ƒé€»è¾‘)
    # æ³¨æ„: æˆ‘ä»¬ä¸å†æ‰‹åŠ¨ä¼ å…¥ chat_history, è€Œæ˜¯è®© memory å¯¹è±¡è‡ªåŠ¨å¤„ç†
    tutor_chain = LLMChain(llm=llm, prompt=prompt, memory=memory)
    
    # 4. è°ƒç”¨ Chain, è®© Memory è‡ªåŠ¨æ›´æ–° Redis
    # .invoke() æ–¹æ³•ä¼šè‡ªåŠ¨: åŠ è½½å†å² -> è¿è¡Œ LLM -> å°†æ–°é—®ç­”å¯¹å­˜å› Redis
    response = tutor_chain.invoke({"question": user_input})
    
    return response["text"]

# --- 4. FastAPI è·¯ç”± (å¼‚æ­¥) ---
@app.websocket("/ws/{client_id}")
async def websocket_endpoint(websocket: WebSocket, client_id: str):
    global led_controller_connection  # global å£°æ˜å¿…é¡»åœ¨å‡½æ•°å¼€å¤´
    await websocket.accept()
    client_ip = websocket.client.host
    print(f"\næ–°çš„å®¢æˆ·ç«¯è¿æ¥: {client_ip} (ID: {client_id})")

    # ä¸ºæ¯ä¸ªè¿æ¥ç»´æŠ¤ä¸€ä¸ªç‹¬ç«‹çš„çŠ¶æ€
    client_state = {
        "is_recording": False,
        "audio_buffer": bytearray()
    }

    try:
        while True:
            message = await websocket.receive()

            # --- å¤„ç†æ–‡æœ¬æ¶ˆæ¯ (JSON äº‹ä»¶) ---
            if "text" in message:
                text = message["text"]
                
                # å¤„ç† LED æ§åˆ¶ä¿¡å· "1" å’Œ "0"
                if text == "1" or text == "0":
                    if led_controller_connection:
                        try:
                            await led_controller_connection.send_text(text)
                            print(f"[{client_ip}] è½¬å‘è¯´è¯çŠ¶æ€ '{text}' åˆ° LED æ§åˆ¶å™¨")
                        except Exception as e:
                            print(f"è½¬å‘åˆ° LED æ§åˆ¶å™¨å¤±è´¥: {e}")
                            led_controller_connection = None  # global å·²åœ¨å‡½æ•°å¼€å¤´å£°æ˜
                    continue
                
                data = json.loads(text)
                event = data.get("event")

                if event == "wake_word_detected":
                    print(f"[{client_ip}] æ£€æµ‹åˆ°å”¤é†’è¯ï¼")

                elif event == "recording_started":
                    print(f"[{client_ip}] å¼€å§‹å½•éŸ³...")
                    client_state["is_recording"] = True
                    client_state["audio_buffer"].clear()

                elif event == "recording_ended":
                    print(f"[{client_ip}] å½•éŸ³ç»“æŸ")
                    client_state["is_recording"] = False
                    
                    if not client_state["audio_buffer"]:
                        print("è­¦å‘Šï¼šéŸ³é¢‘ç¼“å†²åŒºä¸ºç©ºï¼Œä¸å¤„ç†ã€‚")
                        continue

                    print(f"  - éŸ³é¢‘æ€»å¤§å°: {len(client_state['audio_buffer'])} å­—èŠ‚")
                    print("  - å¼€å§‹ AI å¤„ç†æµç¨‹...")

                    # 1. ASR
                    user_text = await asyncio.to_thread(transcribe_audio_stream, bytes(client_state['audio_buffer']))
                    if not user_text:
                        print("  - ASR å¤±è´¥ï¼Œå¯¹è¯ä¸­æ­¢ã€‚")
                        continue
                    print(f"  -  ç”¨æˆ·è¯´ (ASR): '{user_text}'")

                    # 2. LLM
                    ai_response_text = await asyncio.to_thread(get_ai_response_with_redis, user_text, client_id)
                    print(f"  - AI å›å¤: '{ai_response_text}'")

                    # 3. TTS
                    response_audio_bytes = await asyncio.to_thread(synthesize_speech_stream, ai_response_text)
                    if not response_audio_bytes:
                        print("  -  TTS å¤±è´¥ï¼Œå¯¹è¯ä¸­æ­¢ã€‚")
                        continue
                    
                    # çŸ­æš‚å»¶æ—¶ï¼Œç¡®ä¿æ–‡æœ¬å…ˆè¢«å¤„ç†
                    await asyncio.sleep(0.1)
                    
                    # 4. ã€æ–°ç­–ç•¥ã€‘åˆ†å—å‘é€éŸ³é¢‘å› ESP32 (Burst and Yield)
                    print(f"  -  å¼€å§‹æµå¼å‘é€ {len(response_audio_bytes)} å­—èŠ‚çš„å›å¤éŸ³é¢‘...")
                    CHUNK_SIZE = 1024  # æ¯æ¬¡å‘é€çš„æ•°æ®å—å¤§å°
                    BURST_SIZE = 8     # å®šä¹‰ä¸€æ¬¡â€œçˆ†å‘â€å‘é€å¤šå°‘ä¸ªæ•°æ®å— (8 * 1024 = 8KB)
                    burst_count = 0

                    for i in range(0, len(response_audio_bytes), CHUNK_SIZE):
                        chunk = response_audio_bytes[i:i + CHUNK_SIZE]
                        
                        try:
                            await websocket.send_bytes(chunk)
                            burst_count += 1
                            
                            # æ¯å‘é€ BURST_SIZE ä¸ªæ•°æ®å—åï¼Œå°±â€œè°¦è®©â€ä¸€æ¬¡
                            if burst_count >= BURST_SIZE:
                                burst_count = 0
                                # ä½¿ç”¨æå°çš„ä¼‘çœ æ¥è®©å‡ºæ§åˆ¶æƒï¼Œé˜²æ­¢é˜»å¡
                                await asyncio.sleep(0.001)

                        except Exception as e:
                            print(f"\n  åœ¨å‘é€éŸ³é¢‘æ—¶å®¢æˆ·ç«¯æ–­å¼€è¿æ¥: {e}")
                            break

                    # ç¡®ä¿åœ¨ ESP32 å®¢æˆ·ç«¯è°ƒç”¨ finishStreamingPlayback()
                    # æˆ‘ä»¬å¯ä»¥å‘é€ä¸€ä¸ªç‰¹æ®Šçš„JSONæ¶ˆæ¯ä½œä¸ºç»“æŸæ ‡å¿—
                    try:
                        await websocket.send_text(json.dumps({"event": "response_finished"}))

                        # await websocket.close()
                        # break
                    except Exception:
                        pass # å¦‚æœæ­¤æ—¶å®¢æˆ·ç«¯å·²æ–­å¼€ï¼Œå¿½ç•¥é”™è¯¯

                    print(" å¯¹è¯æµç¨‹ç»“æŸ\n")

                elif event == "recording_cancelled":
                    print(f"  [{client_ip}] å½•éŸ³å–æ¶ˆ")
                    client_state["is_recording"] = False
                    client_state["audio_buffer"].clear()

            # --- å¤„ç†äºŒè¿›åˆ¶æ¶ˆæ¯ (éŸ³é¢‘æ•°æ®) ---
            elif "bytes" in message:
                if client_state["is_recording"]:
                    audio_chunk = message["bytes"]
                    client_state["audio_buffer"].extend(audio_chunk)
                    # ä¸ºäº†é¿å…åˆ·å±ï¼Œå¯ä»¥æ³¨é‡Šæ‰ä¸‹é¢è¿™è¡Œ
                    # print(f"  æ¥æ”¶åˆ°éŸ³é¢‘æ•°æ®å—: {len(audio_chunk)} å­—èŠ‚ (æ€»è®¡: {len(client_state['audio_buffer'])})")

    except WebSocketDisconnect:
        print(f" [{client_ip}] å®¢æˆ·ç«¯æ–­å¼€è¿æ¥")
    except Exception as e:
        print(f" [{client_ip}] è¿æ¥å‡ºç°æœªçŸ¥é”™è¯¯: {e}")
    finally:
        # æ— è®ºå¦‚ä½•ï¼Œç¡®ä¿è¿æ¥è¢«å…³é—­ï¼ˆå¦‚æœå®ƒä»ç„¶æ‰“å¼€ï¼‰
        # æ£€æŸ¥çŠ¶æ€ä»¥é¿å…åœ¨å·²ç»å…³é—­çš„è¿æ¥ä¸Šå†æ¬¡å…³é—­
        if websocket.client_state != WebSocketState.DISCONNECTED:
            await websocket.close()
            print(f"[{client_ip}] æœåŠ¡å™¨ç«¯å¼ºåˆ¶å…³é—­è¿æ¥ã€‚")
        # # ç¡®ä¿å³ä½¿å‡ºé”™ä¹Ÿå…³é—­è¿æ¥
        # if websocket.client_state != "DISCONNECTED":
        #     await websocket.close()

# --- 5. LEDæ§åˆ¶å™¨ WebSocket ç«¯ç‚¹ ---
@app.websocket("/ws/led")
async def led_websocket_endpoint(websocket: WebSocket):
    """
    ä¾›ç»„å‘˜çš„ESP32è¿æ¥ï¼Œæ¥æ”¶è¯´è¯çŠ¶æ€æ§åˆ¶LED
    """
    global led_controller_connection
    await websocket.accept()
    led_controller_connection = websocket
    print("ğŸŸ¢ LEDæ§åˆ¶å™¨å·²è¿æ¥")
    
    try:
        while True:
            # ä¿æŒè¿æ¥ï¼Œç­‰å¾…æ–­å¼€
            data = await websocket.receive_text()
            print(f"LEDæ§åˆ¶å™¨æ¶ˆæ¯: {data}")
    except WebSocketDisconnect:
        print("ğŸ”´ LEDæ§åˆ¶å™¨æ–­å¼€è¿æ¥")
    except Exception as e:
        print(f"LEDæ§åˆ¶å™¨è¿æ¥é”™è¯¯: {e}")
    finally:
        led_controller_connection = None

# --- 6. è¿è¡ŒæœåŠ¡å™¨ ---
if __name__ == "__main__":
    import uvicorn
    # å®˜æ–¹ç¤ºä¾‹é»˜è®¤ä½¿ç”¨ 8888 ç«¯å£
    port = 8000
    print("=" * 60)
    print("ğŸ™ï¸ å°æ™ºæ™ºèƒ½éŸ³ç®±æœåŠ¡å™¨")
    print(f"ğŸŒ ç›‘å¬: http://0.0.0.0:{port}")
    print(f"ğŸ”Œ WebSocket: ws://<IP>:8888/ws/esp32")
    print(f"ğŸ’¡ LEDç«¯ç‚¹: ws://<IP>:8888/ws/led")
    print("=" * 60)
    
    uvicorn.run(app, host="0.0.0.0", port=port)

